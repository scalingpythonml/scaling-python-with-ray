{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask local GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a81f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a2ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask Kube GPU\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "from dask_kubernetes import KubeCluster, make_pod_spec\n",
    "#tag::worker_template_with_gpu[]\n",
    "worker_template = make_pod_spec(image='holdenk/dask:latest',\n",
    "                         memory_limit='8G', memory_request='8G',\n",
    "                         cpu_limit=1, cpu_request=1)\n",
    "worker_template.spec.containers[0].resources.limits[\"gpu\"] = 1\n",
    "worker_template.spec.containers[0].resources.requests[\"gpu\"] = 1\n",
    "worker_template.spec.containers[0].args[0] = \"dask-cuda-worker\"\n",
    "worker_template.spec.containers[0].env.append(\"NVIDIA_VISIBLE_DEVICES=ALL\")\n",
    "# Or append --resources \"GPU=2\"\n",
    "#end::worker_template_with_gpu[]\n",
    "#tag::worker_template_with_label[]\n",
    "worker_template = make_pod_spec(image='holdenk/dask:latest',\n",
    "                         memory_limit='8G', memory_request='8G',\n",
    "                         cpu_limit=1, cpu_request=1)\n",
    "worker_template.spec.node_selector = \"node.kubernetes.io/gpu=gpu\"\n",
    "worker_template.spec.containers[0].args[0] = \"dask-cuda-worker\"\n",
    "worker_template.spec.containers[0].env.append(\"NVIDIA_VISIBLE_DEVICES=ALL\")\n",
    "worker_template.spec.\n",
    "# Or append --resources \"GPU=2\"\n",
    "#end::worker_template_with_label[]\n",
    "scheduler_template = make_pod_spec(image='holdenk/dask:latest',\n",
    "                         memory_limit='4G', memory_request='4G',\n",
    "                         cpu_limit=1, cpu_request=1)\n",
    "cluster = KubeCluster(pod_template = worker_template, scheduler_pod_template = scheduler_template, namespace=\"dask\")\n",
    "cluster.adapt()    # or create and destroy workers dynamically based on workload\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56cb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user git+https://github.com/dask/dask-kubernetes.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b199fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_template.spec.containers[0].env.append(\"NVIDIA_VISIBLE_DEVICES=ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1efa04e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
