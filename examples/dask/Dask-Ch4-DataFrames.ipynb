{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab408b22-f512-45c6-bb91-54c14364500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from typing import *\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b967e-f8f8-4108-a1cf-6bbd42130f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://gender-pay-gap.service.gov.uk/viewing/download-data/2021\"\n",
    "#tag::ex_load_1kb[]\n",
    "many_chunks = dd.read_csv(url, blocksize=\"1kb\")\n",
    "many_chunks.index\n",
    "#end::ex_load_1kb[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5219c060-b3ed-4231-9216-9602bef87fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::ex_load_uk_gender_pay_gap_infered[]\n",
    "df = dd.read_csv(\n",
    "    \"https://gender-pay-gap.service.gov.uk/viewing/download-data/2021\")\n",
    "#end::ex_load_uk_gender_pay_gap_infered[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a756431f-cd9d-4b45-9232-a39f65927cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The df.compute() is not needed for the load, but because Dask is lazy we need to trigger a compute\n",
    "# for Dask to evaluate the DataFrame and notice the error.\n",
    "try:\n",
    "    df.compute() # Observe the failure\n",
    "except Exception as e:\n",
    "        print(e)\n",
    "# - CompanyNumber\n",
    "#  ValueError(\"invalid literal for int() with base 10: 'SC312912'\")\n",
    "#end::ex_load_uk_gender_pay_gap_infered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b790327d-2597-40c4-9c87-e9f7c0d3baec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::ex_load_uk_gender_pay_gap[]\n",
    "df = dd.read_csv(\n",
    "    \"https://gender-pay-gap.service.gov.uk/viewing/download-data/2021\",\n",
    "    dtype={'CompanyNumber': 'str', 'DiffMeanHourlyPercent': 'float64'})\n",
    "#end::ex_load_uk_gender_pay_gap[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e9732-a1a8-406a-ae4f-0e340a6d22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::csv_gender_pay_gap_with_full_inference[]\n",
    "df = dd.read_csv(\n",
    "    \"https://gender-pay-gap.service.gov.uk/viewing/download-data/2021\",\n",
    "    sample=256000000000000000000000000000000000000000000) # size in bytes to sample\n",
    "# One day this should work, but for now it does not and we get the same error as if we had not sampled the entire CSV file\n",
    "# df.compute()\n",
    "#end::csv_gender_pay_gap_with_full_inference[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c8f8d3-093f-44a2-b8d0-611b46b0e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fsspec.registry import known_implementations\n",
    "known_implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318e776-4438-449f-8f6b-ef9f7204b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::filna_ex[]\n",
    "def fillna(df):\n",
    "    return df.fillna(value={\"PostCode\": \"UNKNOWN\"}).fillna(value=0)\n",
    "    \n",
    "new_df = df.map_partitions(fillna)\n",
    "# Since there could be an NA in the index clear the partition / division information\n",
    "new_df.clear_divisions()\n",
    "#end::filna_ex[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6499e70-c4d1-4c41-b18f-fd7435b824c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ef918f-b2cd-4208-97b4-32ea5dfff416",
   "metadata": {},
   "outputs": [],
   "source": [
    "narrow_df = new_df[[\"PostCode\", \"EmployerSize\", \"DiffMeanHourlyPercent\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aadf339-9433-4ea2-8951-313ca54e9ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = narrow_df.groupby(\"PostCode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3589b30-ad2f-4c47-acec-1631e9a4045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_grouped_df = new_df.groupby([\"PostCode\", \"SicCodes\"])\n",
    "alt_grouped_df.sum().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32c708-e23c-4ea4-aff4-f246bde2920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_by_postalcode = grouped_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dea154-089c-497f-9f3f-6fb974745852",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_by_postalcode.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a233a781-5601-49b8-a5ab-2e4220f45427",
   "metadata": {},
   "outputs": [],
   "source": [
    "ops_by_postcalcode = narrow_df.set_index(\"PostCode\", npartitions=10)\n",
    "len(list(ops_by_postcalcode.partitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eaec23-cae4-40bb-85a0-b479d3938c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le sad, you can see this doesn't actually respect the partition size of one byte.\n",
    "dask.visualize(narrow_df.set_index(\"PostCode\", npartitions=\"auto\", partition_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22d1720-0cde-41b3-8abb-905e2a794e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed = narrow_df.set_index(\"PostCode\")\n",
    "#tag::repartition[]\n",
    "reparted = indexed.repartition(partition_size=\"20kb\")\n",
    "#end::repartition[]\n",
    "dask.visualize(narrow_df.set_index(\"PostCode\").repartition(partition_size=\"20kb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23db2ff-3261-4547-aeb2-289a7b6fe2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(ops_by_postcalcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e80386f-7bbe-4004-bc46-40240c8aa2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_grouped_df = ops_by_postcalcode.groupby(\"PostCode\")\n",
    "fast_grouped_df.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b02798-86f7-4c5f-ac68-c05e0d2f71de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kind of hacky string munging to get a median-ish to weight our values.\n",
    "def update_empsize_to_median(df):\n",
    "    def to_median(value):\n",
    "        if \" to \" in value:\n",
    "            f , t = value.replace(\",\", \"\").split(\" to \")\n",
    "            return (int(f) + int(t)) / 2.0\n",
    "        elif \"Less than\" in value:\n",
    "            return 100\n",
    "        else:\n",
    "            return 10000\n",
    "    df[\"EmployerSize\"] = df[\"EmployerSize\"].apply(to_median)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_with_median_emp_size = narrow_df.map_partitions(update_empsize_to_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed08355-4b18-464e-a0e6-d8dc342940f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e55162-d7e5-4cbd-b634-0251e1576ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_median_emp_size.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a94c09-163a-415a-95af-9473a59625d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_emp_with_diff(df):\n",
    "    # In practice life would be easier if we multiplied these together but to illustrate\n",
    "    # the custom aggregate we'll make this a tuple for now\n",
    "    df[\"empsize_diff\"] = list(df[[\"EmployerSize\", \"DiffMeanHourlyPercent\"]].to_records(index=False))\n",
    "    return df\n",
    "df_diff_with_emp_size = df_with_median_emp_size.map_partitions(\n",
    "    join_emp_with_diff)\n",
    "df_diff_with_emp_size.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d644b8-84f7-4970-b8a6-b2cad10abd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::custom_agg[]\n",
    "# Write a custom weighted mean, we get either a DataFrameGroupBy with multiple columns or SeriesGroupBy for each chunk\n",
    "def process_chunk(chunk):\n",
    "    def weighted_func(df):\n",
    "        return (df[\"EmployerSize\"] * df[\"DiffMeanHourlyPercent\"]).sum()\n",
    "    return (chunk.apply(weighted_func), chunk.sum()[\"EmployerSize\"])\n",
    "        \n",
    "def agg(total, weights):\n",
    "    return (total.sum(), weights.sum())\n",
    "\n",
    "def finalize(total, weights):\n",
    "    return total / weights\n",
    "    \n",
    "weighted_mean = dd.Aggregation(\n",
    "    name='weighted_mean',\n",
    "    chunk=process_chunk,\n",
    "    agg=agg,\n",
    "    finalize=finalize)\n",
    "\n",
    "aggregated = df_diff_with_emp_size.groupby(\"PostCode\")[\"EmployerSize\", \"DiffMeanHourlyPercent\"].agg(weighted_mean)\n",
    "#end::custom_agg[]\n",
    "j = aggregated.head(4)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62c6c3f-419b-4e1b-a26d-640d5f77e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::custom_agg_hyperloglog[]\n",
    "# Wrap Dask's hyperloglog in dd.Aggregation\n",
    "\n",
    "from dask.dataframe import hyperloglog\n",
    "\n",
    "approx_unique = dd.Aggregation(\n",
    "    name='aprox_unique',\n",
    "    chunk=hyperloglog.compute_hll_array,\n",
    "    agg=hyperloglog.reduce_state,\n",
    "    finalize=hyperloglog.estimate_count)\n",
    "\n",
    "aggregated = df_diff_with_emp_size.groupby(\"PostCode\")[\"EmployerSize\", \"DiffMeanHourlyPercent\"].agg(weighted_mean)\n",
    "#end::custom_agg_hyperloglog[]\n",
    "j = aggregated.head(4)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3eda1a-c3b0-4c48-a51d-212b00e47aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = new_df.groupby(\"PostCode\")[\"EmployerId\"].apply(lambda g: list(g))\n",
    "aggregated.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a605dbb2-7325-4e19-bcef-a7f148e809a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loading data example the note here is that whatever params we pass through read_x\n",
    "# if not consumed by dask (e.g. blocksize is used by Dask), \n",
    "# More generally all of Dask's DataFrame functions follow this pattern.\n",
    "sf_covid_df = dd.read_csv(\"https://data.sfgov.org/api/views/gqw3-444p/rows.csv?accessType=DOWNLOAD\", blocksize=None, dtype={\n",
    "    'pct_tot_new_cases': 'float64',\n",
    "    'pct_tot_new_cases_7_day_avg': 'float64',\n",
    "    'new_case_rate': 'float64',\n",
    "    'new_case_rate_7_day_avg': 'float64',\n",
    "    'new_cases_7_day_avg': 'float64'}, parse_dates=['specimen_collection_date'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d5ebf1-f769-42f0-9435-20510a555cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_covid_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e451f9-f2d5-4db4-84bd-18546f6fa83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_covid_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c78ec6-d8d5-4326-a8bd-ccd352bc3a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::compute_entire_max_mean[]\n",
    "dask.compute(\n",
    "    sf_covid_df[[\"new_cases\"]].max(),\n",
    "    sf_covid_df[[\"new_cases\"]].mean()\n",
    ")\n",
    "#end::compute_entire_max_mean[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370caaa9-a586-433f-8e80-51f652e87c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::static_group[]\n",
    "raw_grouped = sf_covid_df.groupby(lambda x: 0)\n",
    "#end::static_group[]\n",
    "\n",
    "#tag::max_mean[]\n",
    "dask.compute(\n",
    "    raw_grouped[[\"new_cases\"]].max(),\n",
    "    raw_grouped[[\"new_cases\"]].mean())\n",
    "#end::max_mean[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719de1d6-022b-40a0-b5de-d6683d0e0864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns & rows we don't care about before repartitioning\n",
    "#tag::index_covid_data[]\n",
    "mini_sf_covid_df = sf_covid_df[sf_covid_df['vaccination_status'] == 'All'][['specimen_collection_date', 'new_cases']]\n",
    "#end::index_covid_data[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d3a026-0a74-4737-8de3-821ba1cb6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_sf_covid_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd672e6-7f2f-4419-af1f-f6e4f68c7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df = mini_sf_covid_df.set_index('specimen_collection_date', npartitions=5)\n",
    "indexed_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc47085f-f7fd-44d6-809f-4a3538064fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#tag::set_index_with_rolling_window[]\n",
    "divisions = pd.date_range(start=\"2021-01-01\", end=datetime.today(), freq='7D').tolist()\n",
    "partitioned_df_as_part_of_set_index = mini_sf_covid_df.set_index(\n",
    "    'specimen_collection_date', divisions=divisions)\n",
    "#end::set_index_with_rolling_window[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f138d9-a468-4053-b343-6c9cf2f5f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_df_as_part_of_set_index.divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d3fb1-6d93-4724-b96e-616efa94caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(indexed_df.partitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cde7a13-3d6d-4b42-8e57-1aed09203c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repartition on 14 day window\n",
    "partitioned_df = indexed_df.repartition(freq='14D', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30611d85-a7c7-43e6-b615-37a086907d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_df.divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b92290-a9e3-4bf5-a02a-e4f398d26686",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_df.divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed44e70d-a69d-431f-a6df-648a005b430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling average with time delta\n",
    "#tag::rolling_date_ex[]\n",
    "rolling_avg = partitioned_df.map_overlap(lambda df: df.rolling('5D').mean(), pd.Timedelta('5D'), 0)\n",
    "#end::rolling_date_ex[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdadfbb-11d3-4256-8f04-ef3b9d011616",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_avg.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b82a23e-b17d-423f-b597-590def0d0fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
