{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfead8d3-4364-4435-a25d-59d4375f8562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-macosx_10_11_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tokenizers\n",
      "Successfully installed tokenizers-0.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1203716a-b958-4933-9924-8db230a74927",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 10.4 MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Installing collected packages: huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.8.1 transformers-4.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64184d73-5c07-482e-b5ee-ce9339bf3727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.9/site-packages (4.64.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d45eeb6-f666-4491-8471-fc3b5ab2785f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.12.0-cp39-none-macosx_10_9_x86_64.whl (133.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 133.6 MB 173 kB/s eta 0:00:013    |████▉                           | 20.1 MB 14.1 MB/s eta 0:00:09     |███████▍                        | 30.9 MB 12.0 MB/s eta 0:00:09     |█████████▊                      | 40.7 MB 13.8 MB/s eta 0:00:074.7 MB/s eta 0:00:10\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.9/site-packages (from torch) (4.1.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47b4bf11-75e0-4e8a-956d-3a4c9a33e7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/distributed/node.py:177: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 55330 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "# when working with clusters, specify cluster config, n_workers and worker_size\n",
    "client = Client(n_workers=4, \n",
    "                       threads_per_worker=1,\n",
    "                       memory_limit=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3186dc16-827a-4dbe-a924-1bedf59de550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ae5fd7-eaef-4e36-944d-65038b7f9fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "390fbcf7-e87d-4e99-998c-32ddbb8746ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-d94c3bfc-06f2-11ed-853f-acde48001122</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:55330/status\" target=\"_blank\">http://127.0.0.1:55330/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">3b9b718f</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:55330/status\" target=\"_blank\">http://127.0.0.1:55330/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 4\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 4\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-0873273a-0ea7-4443-a3ce-a1945a510593</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:55331\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 4\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:55330/status\" target=\"_blank\">http://127.0.0.1:55330/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 4\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:55347\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:55354/status\" target=\"_blank\">http://127.0.0.1:55354/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:55336\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /Users/mika.kimmins/projects/scalingpythonml/dask/dask-worker-space/worker-lowktdq8\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:55348\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:55351/status\" target=\"_blank\">http://127.0.0.1:55351/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:55334\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /Users/mika.kimmins/projects/scalingpythonml/dask/dask-worker-space/worker-blm211kh\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 2</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:55349\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:55353/status\" target=\"_blank\">http://127.0.0.1:55353/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:55335\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /Users/mika.kimmins/projects/scalingpythonml/dask/dask-worker-space/worker-qqdfgyha\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 3</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:55350\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:55352/status\" target=\"_blank\">http://127.0.0.1:55352/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:55337\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /Users/mika.kimmins/projects/scalingpythonml/dask/dask-worker-space/worker-72uyo4gt\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:55331' processes=4 threads=4>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b8d04-6ad5-417a-a2d3-7fd70c95770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/facebookresearch/fairseq/blob/main/examples/translation/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ddfda-4fa9-4324-b2a6-a48c7802988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/abhishek/roberta-inference-5-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b90750-2885-4d51-ac79-7b97eb2fe380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tokenizers\n",
    "import string\n",
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d0feff-1731-47fe-96cd-19995485e7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import( DistilBertConfig,\n",
    "                                           DistilBertForMaskedLM,\n",
    "                                           LineByLineTextDataset, DistilBertTokenizer, \n",
    "                                           DataCollatorForLanguageModeling,\n",
    "                                          Trainer, TrainingArguments, pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28064fef-eff0-4e8c-8209-72dd4251ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1676c661-55ee-4ba5-b737-772dd385aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96221f4-b206-47cf-847f-b4f54f207d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 192\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "# ROBERTA_PATH = \"../input/roberta-base\"\n",
    "# TOKENIZER = tokenizers.ByteLevelBPETokenizer(\n",
    "#     vocab_file=f\"{ROBERTA_PATH}/vocab.json\", \n",
    "#     merges_file=f\"{ROBERTA_PATH}/merges.txt\", \n",
    "#     lowercase=True,\n",
    "#     add_prefix_space=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "154a176c-a011-4a08-a396-d8c96bfc9641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/roberta-base\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaModel.from_pretrained('roberta-base')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e31ad0-5a96-4771-a14d-4a1ad257cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/arvissu/roberta-base-inference-v2-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5546b6be-ac2f-4567-8133-14395a989eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4f9c5bd8-9186-493f-b8eb-cfdd79c1f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import dask.bag as bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effdf853-4ebe-40dd-a4f6-448cba2aa648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the model\n",
    "# download the datasets from kaggle\n",
    "# dataset: https://www.kaggle.com/competitions/feedback-prize-effectiveness/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b017fcf-26b0-4bc5-b8d8-45148ffc20e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c118bc75-6c57-466b-ba6e-7eb6d26447cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "FOLDS = 4\n",
    "lr = 2e-5\n",
    "SEED = 2018\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 8\n",
    "accumulation_steps = 4\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db032274-2a5a-4f4e-95f1-8523aa011bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class callback:\n",
    "    def __init__(self):\n",
    "        self.loss = list()\n",
    "        self.model = list()\n",
    "    \n",
    "    def put(self, model, loss):\n",
    "        self.loss.append(loss)\n",
    "        self.model.append(model)\n",
    "\n",
    "    def get_model(self):\n",
    "        ind = np.argmin(self.loss)\n",
    "        return self.model[ind]\n",
    "\n",
    "    \n",
    "class FeedBackModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(FeedBackModel, self).__init__()\n",
    "        self.model = model\n",
    "        # self.model = AutoModel.from_pretrained(model_path)\n",
    "        self.linear = nn.Linear(768, 3)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        x = self.model(ids, mask)[0][:, 0, :]\n",
    "        pred = self.linear(x)\n",
    "        return pred\n",
    "\n",
    "\n",
    "class FeedBackDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, is_test=False):\n",
    "        self.data = data\n",
    "        self.is_test = is_test\n",
    "        self.tokenizer = tokenizer\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data['discourse_text'].values[idx] + ' ' + self.tokenizer.sep_token*2  + ' '  + self.data['essay'].values[idx]\n",
    "        if not self.is_test:\n",
    "            target_value = self.data[y_cols].values[idx]\n",
    "      \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_LEN\n",
    "        )['input_ids'] \n",
    "        \n",
    "                  \n",
    "        mask = [1]*len(inputs) + [0] * (MAX_LEN - len(inputs)) \n",
    "        mask = torch.tensor(mask, dtype=torch.long)\n",
    "        \n",
    "        if len(inputs) != MAX_LEN:\n",
    "            inputs = inputs + [self.tokenizer.pad_token_id] * (MAX_LEN - len(inputs)) \n",
    "        ids = torch.tensor(inputs, dtype=torch.long)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.is_test:\n",
    "            return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            targets = torch.FloatTensor(target_value)\n",
    "            return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'targets': targets\n",
    "            }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2b767a1-31d9-4de0-88b0-ede639bd1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "042ab23a-2ff4-408e-ab2c-da6b5171eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \"\"\"Return the model and tokenizer\"\"\"\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")\n",
    "\n",
    "    # tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "    # model = RobertaForSequenceClassification.from_pretrained(model_path, return_dict=True)\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "190d5af0-5a2e-4bf5-9049-46460181d738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer, model = load_model()\n",
    "\n",
    "dmodel = dask.delayed(model.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f207e-17ab-47a4-a082-85453c64261a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be6346a4-61b0-4dd0-b322-a1f80fc68cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cols = ['discourse_effectiveness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "99a1c67e-10f9-44d8-a017-6e7f2dc0f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask portion\n",
    "root_src = \"./kaggle/feedback-prize-effectiveness/\"\n",
    "ESSAY_ROOT_PATH = root_src\n",
    "train_src = root_src + \"train.csv\"\n",
    "ddf = dd.read_csv(train_src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "0da73cd6-a684-4ce1-9006-05eee2e03731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  \n",
       "0                Adequate  \n",
       "1                Adequate  \n",
       "2                Adequate  \n",
       "3                Adequate  \n",
       "4                Adequate  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a240c997-2fda-4fbb-af54-36a8ee9464e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8d2dcaea-d6e7-4d6d-ade3-6644c6f6ea03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f822d513-4b8f-46f9-ac9c-4b662481d8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "75299afb-7784-43a3-9177-97b55afd3f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a df with the files\n",
    "# http://sujitpal.blogspot.com/2020/06/dask-mappartitions-and-almost.html\n",
    "filepaths = []\n",
    "for filepath in glob.iglob(ESSAY_ROOT_PATH + \"train/*.txt\", recursive=True):\n",
    "    filepaths.append(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "49d9a395-a325-44c8-99b6-c5c594a9b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_df = (bag.from_sequence(filepaths, partition_size=100)\n",
    "      .map(lambda fp: { \"filepath\": fp })\n",
    "      .to_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c55a5-a1d8-4e7a-ad60-e36cc0d61837",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c3e91a87-6768-481c-bc57-673dbdd8fb83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def fetchEssay(essay_path):\n",
    "#     \"\"\"\n",
    "#     Read the text file of the specific essay_id\n",
    "#     \"\"\"\n",
    "#     # return \"blahblah\"\n",
    "#     print(essay_path)\n",
    "#     print(\"opening path\" + essay_path)\n",
    "#     essay_text = open(essay_path, 'r').read()\n",
    "#     return essay_text\n",
    "\n",
    "# def handle_row(row):\n",
    "#     return \"san francisco\"\n",
    "#     # return row\n",
    "\n",
    "# def handle_read_partition_(part):\n",
    "#     # result = part.apply(lambda row: handle_row(row), axis=1)\n",
    "#     result[\"txt\"] = part.apply(lambda row: handle_row(row), axis=1)\n",
    "#     # df[\"txt\"] = df[\"filepath\"].apply(fetchEssay)\n",
    "#     return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "5d413388-0069-4245-9ac7-a33495e646c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>discourse_effectiveness_</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "      <td>san francisco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  discourse_effectiveness_            txt  \n",
       "0                Adequate                         1  san francisco  \n",
       "1                Adequate                         1  san francisco  \n",
       "2                Adequate                         1  san francisco  \n",
       "3                Adequate                         1  san francisco  \n",
       "4                Adequate                         1  san francisco  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# out_df = filepath_df.map_partitions(lambda part : handle_read_partition_(part))\n",
    "\n",
    "# out_df.compute().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba54fad4-57fa-47b7-b270-8d6de9f1259a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eba6c1-34a1-4848-be3f-119bab60bc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec1b5a-6006-4a44-879c-4a5183c4248c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d59aa679-7d41-4371-ac19-813f27dffd43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    opening essay: foo\n",
      "1    opening essay: foo\n",
      "Name: essay_id, dtype: object\n",
      "0    opening full path: ./kaggle/feedback-prize-eff...\n",
      "1    opening full path: ./kaggle/feedback-prize-eff...\n",
      "Name: essay_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# # ddf.map_partitions(lambda df: df.assign (essay = open(df.essay_id + \"train/\" + essay_id + \".txt\", 'r').read()   ) )\n",
    "# def argh(df):\n",
    "#     return df.assign(essay = df['essay_id'])\n",
    "\n",
    "# def fetchEssay_map(df):\n",
    "#     return df.assign(essay_path = open_essay(df['essay_id']))\n",
    "\n",
    "# def open_essay(essay_id):\n",
    "#     full_path = ESSAY_ROOT_PATH + \"train/\" + essay_id + \".txt\"\n",
    "#     print(\"opening essay: \" + essay_id)\n",
    "#     print(\"opening full path: \" + full_path)\n",
    "#     return (full_path)\n",
    "#     # return open(full_path, 'r').read()\n",
    "\n",
    "# # ddf_out = ddf.map_partitions(fetchEssay_map, meta = ('essay', 'f8'))\n",
    "# ddf_out = ddf.map_partitions(fetchEssay_map)\n",
    "# # ddf_out = ddf.map_partitions(argh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "a341af30-2fd1-4b49-9e5f-403a25a9eac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "96aff2cd-94d8-4cfa-ac10-31a5dfb679ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137fab5-fa17-49e8-a288-ced07e72e9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd230a4c-452e-4ead-8741-22110ff6d6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde54965-5013-4cff-af53-6e49548f7926",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "575d831b-13c3-4a57-9427-dd49ad857550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EWWW Don't like this logic.\n",
    "# should be able to do something like this row-wise, but the way this works doesn't allow for that.\n",
    "#  {\"Ineffective\": 0, \"Adequate\": 1, \"Effective\": 2}[effectiveness]\n",
    " \n",
    "def handle_partition(df):\n",
    "    def handle_effectiveness(value):\n",
    "        if \"Ineffective\" in value:\n",
    "            return 0\n",
    "        elif \"Adequate\" in value:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    df[\"discourse_effectiveness_\"] = df[\"discourse_effectiveness\"].apply(handle_effectiveness)\n",
    "    return df\n",
    "\n",
    "ddf_relabled_effectiveness = ddf.map_partitions(handle_partition) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be70c1fa-7aca-48d3-9436-80a6ee09e644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9857f41b-45bf-4988-aeb1-28904ef3ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = ddf_relabled_effectiveness.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "7bba3178-7db8-419b-9202-6b22ff1edfc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>discourse_effectiveness_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36a565e45db7</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>though some say that life on Mars does exist, ...</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>Ineffective</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fb65fe816ba3</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>It says in paragraph 7, on April 5, 1998, Mars...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4e472e2584fa</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Everyone who thought it was made by alieans ev...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28a94d3ee425</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Though people were not satified about how the ...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d226f06362f5</td>\n",
       "      <td>00944C693682</td>\n",
       "      <td>Limiting the usage of cars has personal and pr...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Effective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>de347c859ab6</td>\n",
       "      <td>00944C693682</td>\n",
       "      <td>With so many things in this world that few peo...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Effective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cc921c5cfda4</td>\n",
       "      <td>00944C693682</td>\n",
       "      <td>stress.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a6fcdd9110ab</td>\n",
       "      <td>00944C693682</td>\n",
       "      <td>It is no secret that morning traffic jams and ...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Effective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6efd9102298b</td>\n",
       "      <td>00944C693682</td>\n",
       "      <td>the environment suffers greatly from the many ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Effective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>d6807f31da92</td>\n",
       "      <td>00944C693682</td>\n",
       "      <td>\"Passenger cars are responsible for 12 percent...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Effective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>024f3edf0cdb</td>\n",
       "      <td>00944C693682</td>\n",
       "      <td>, adding the last two reasons together makes f...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Effective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cf5dc6eb65e0</td>\n",
       "      <td>00944C693682</td>\n",
       "      <td>If it must be described as \"emissions ... are ...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8df2da9994bf</td>\n",
       "      <td>00944C693682</td>\n",
       "      <td>It is also worth noting that cities that have ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Effective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>033845420f01</td>\n",
       "      <td>00944C693682</td>\n",
       "      <td>In Vauban, \"stores are placed a walk away, on ...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Effective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9fd314f638e5</td>\n",
       "      <td>00944C693682</td>\n",
       "      <td>Individual car use isn't bad. Millions of indi...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Effective</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    discourse_id      essay_id  \\\n",
       "0   0013cc385424  007ACE74B050   \n",
       "1   9704a709b505  007ACE74B050   \n",
       "2   c22adee811b6  007ACE74B050   \n",
       "3   a10d361e54e4  007ACE74B050   \n",
       "4   db3e453ec4e2  007ACE74B050   \n",
       "5   36a565e45db7  007ACE74B050   \n",
       "6   fb65fe816ba3  007ACE74B050   \n",
       "7   4e472e2584fa  007ACE74B050   \n",
       "8   28a94d3ee425  007ACE74B050   \n",
       "9   d226f06362f5  00944C693682   \n",
       "10  de347c859ab6  00944C693682   \n",
       "11  cc921c5cfda4  00944C693682   \n",
       "12  a6fcdd9110ab  00944C693682   \n",
       "13  6efd9102298b  00944C693682   \n",
       "14  d6807f31da92  00944C693682   \n",
       "15  024f3edf0cdb  00944C693682   \n",
       "16  cf5dc6eb65e0  00944C693682   \n",
       "17  8df2da9994bf  00944C693682   \n",
       "18  033845420f01  00944C693682   \n",
       "19  9fd314f638e5  00944C693682   \n",
       "\n",
       "                                       discourse_text        discourse_type  \\\n",
       "0   Hi, i'm Isaac, i'm going to be writing about h...                  Lead   \n",
       "1   On my perspective, I think that the face is a ...              Position   \n",
       "2   I think that the face is a natural landform be...                 Claim   \n",
       "3   If life was on Mars, we would know by now. The...              Evidence   \n",
       "4   People thought that the face was formed by ali...          Counterclaim   \n",
       "5   though some say that life on Mars does exist, ...              Rebuttal   \n",
       "6   It says in paragraph 7, on April 5, 1998, Mars...              Evidence   \n",
       "7   Everyone who thought it was made by alieans ev...          Counterclaim   \n",
       "8   Though people were not satified about how the ...  Concluding Statement   \n",
       "9   Limiting the usage of cars has personal and pr...                  Lead   \n",
       "10  With so many things in this world that few peo...              Position   \n",
       "11                                           stress.                  Claim   \n",
       "12  It is no secret that morning traffic jams and ...              Evidence   \n",
       "13  the environment suffers greatly from the many ...                 Claim   \n",
       "14  \"Passenger cars are responsible for 12 percent...              Evidence   \n",
       "15  , adding the last two reasons together makes f...                 Claim   \n",
       "16  If it must be described as \"emissions ... are ...              Evidence   \n",
       "17  It is also worth noting that cities that have ...                 Claim   \n",
       "18  In Vauban, \"stores are placed a walk away, on ...              Evidence   \n",
       "19  Individual car use isn't bad. Millions of indi...  Concluding Statement   \n",
       "\n",
       "   discourse_effectiveness  discourse_effectiveness_  \n",
       "0                 Adequate                         1  \n",
       "1                 Adequate                         1  \n",
       "2                 Adequate                         1  \n",
       "3                 Adequate                         1  \n",
       "4                 Adequate                         1  \n",
       "5              Ineffective                         0  \n",
       "6                 Adequate                         1  \n",
       "7                 Adequate                         1  \n",
       "8                 Adequate                         1  \n",
       "9                Effective                         2  \n",
       "10               Effective                         2  \n",
       "11                Adequate                         1  \n",
       "12               Effective                         2  \n",
       "13               Effective                         2  \n",
       "14               Effective                         2  \n",
       "15               Effective                         2  \n",
       "16                Adequate                         1  \n",
       "17               Effective                         2  \n",
       "18               Effective                         2  \n",
       "19               Effective                         2  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d1f05452-faaf-4bed-9940-493add5a4935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6b64b-c9a6-4c16-83f2-622956b625cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd75d7-903d-4c17-a6e0-721cef184172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a18c242-67e7-4c3d-b3d2-67093f053713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0aa48-183e-43e8-af62-f91f38682ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4471c3e-0d78-4076-8fb4-f8ea5319b321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722841d-e01b-4b95-a1dc-38085aea4a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb97612-7df1-49d3-8281-b5b5d043c32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8bed25-0081-4e5b-9e52-526be5bd2a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f619a41-df1f-41be-a7b9-84f09894a675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a31225e-01d6-42c2-aa77-909babfc40fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014bd979-c17b-4d13-b736-612993138284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb19f4d-5eda-4acb-ba11-57f08d78000d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c91983-0ae3-44e8-9d46-4f752c2c5edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296fb295-eea3-402e-b704-5af9a901d2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6894d2-c4e4-407c-81ae-3e705750a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "# https://www.kaggle.com/code/arvissu/roberta-base-training-notebook-1-epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ccc9135e-6bb3-463d-9447-ffac6daf9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = list()\n",
    "kf = StratifiedKFold(n_splits=FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c660675-6527-473f-ae22-6f168bf9329f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "6d96f0b2-1b0e-47c8-882a-f9785632f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_idx = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634cad6-4da2-4021-87ee-ae8b7dd95309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "0341b8c9-1a6d-4653-a4c9-9f11824fbc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0 ,train_idx: [    3     4     5 ... 36762 36763 36764],  valid_idx: [    0     1     2 ... 36747 36760 36761]\n",
      "fold 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [270]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m      7\u001b[0m cb \u001b[38;5;241m=\u001b[39m callback()\n\u001b[0;32m----> 8\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\u001b[43mFeedBackDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      9\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(FeedBackDataset(df\u001b[38;5;241m.\u001b[39mloc[valid_idx :end_idx]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), tokenizer), batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mFeedBackDataset.__init__\u001b[0;34m(self, data, model_path, is_test)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_test \u001b[38;5;241m=\u001b[39m is_test\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:522\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 522\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m config_tokenizer_class \u001b[38;5;241m=\u001b[39m tokenizer_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer_class\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    524\u001b[0m tokenizer_auto_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:380\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_tokenizer_config\u001b[39m(\n\u001b[1;32m    312\u001b[0m     pretrained_model_name_or_path: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    313\u001b[0m     cache_dir: Optional[Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    321\u001b[0m ):\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;124;03m    Loads the tokenizer configuration from a pretrained model tokenizer configuration.\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m    tokenizer_config = get_tokenizer_config(\"tokenizer-test\")\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mget_file_from_repo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/hub.py:687\u001b[0m, in \u001b[0;36mget_file_from_repo\u001b[0;34m(path_or_repo, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only)\u001b[0m\n\u001b[1;32m    683\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_bucket_url(path_or_repo, filename\u001b[38;5;241m=\u001b[39mfilename, revision\u001b[38;5;241m=\u001b[39mrevision, mirror\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 687\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    699\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    700\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    703\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/hub.py:284\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    280\u001b[0m     local_files_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m url_or_filename\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/hub.py:554\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    548\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    549\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find the requested files in the cached path and outgoing traffic has been\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    550\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m disabled. To enable model look-ups and downloads online, set \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_files_only\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    552\u001b[0m                 )\n\u001b[1;32m    553\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 554\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    555\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection error, and we cannot find the requested files in the cached path.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    556\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please try again or make sure your Internet connection is on.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    557\u001b[0m                 )\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# From now on, etag is not None.\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cache_path) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force_download:\n",
      "\u001b[0;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on."
     ]
    }
   ],
   "source": [
    "df = ddf_relabled_effectiveness\n",
    "for i, (train_idx, valid_idx) in enumerate(kf.split(df, y=df['essay_id'])):\n",
    "    print (f\"i: {i} ,train_idx: {train_idx},  valid_idx: {valid_idx}\" )\n",
    "    print(f'fold {i+1}')\n",
    "    gc.collect()\n",
    "    \n",
    "    cb = callback()\n",
    "    train_loader = torch.utils.data.DataLoader(FeedBackDataset(df.loc[train_idx:end_idx].reset_index(drop=True), tokenizer), batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = torch.utils.data.DataLoader(FeedBackDataset(df.loc[valid_idx :end_idx].reset_index(drop=True), tokenizer), batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     net = FeedBackModel(model)\n",
    "#     net.cuda()\n",
    "    \n",
    "#     loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#     optimizer = AdamW(net.parameters(), lr = lr)    \n",
    "#     param_optimizer = list(net.named_parameters())\n",
    "#     no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "#     optimizer_grouped_parameters = [\n",
    "#         {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "#         {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "#     ]\n",
    "#     num_train_optimization_steps = int(EPOCHS * len(train_loader) / accumulation_steps)\n",
    "#     scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.05 * num_train_optimization_steps,\n",
    "#                                                 num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n",
    "#     scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a9a04-8bf5-4e49-8e62-3bc86863014f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7ea355-2716-49d1-a596-d63b92dece47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d5510-b723-4c7e-87ab-157a91afbf10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192ab68e-6188-4182-a43c-b6a555dc91a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f0478-648d-43a3-b221-fa12c9da879e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b717b7-301d-44ae-9b6c-4c2da9347782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9fdb43-6a7a-48a0-93d1-f6381994c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_idx, valid_idx) in enumerate(kf.split(ddf_relabled_effectiveness, y=ddf_relabled_effectiveness['essay_id'])):\n",
    "    print(f'fold {i+1}')\n",
    "    gc.collect()\n",
    "    \n",
    "    cb = callback()\n",
    "    train_loader = torch.utils.data.DataLoader(FeedBackDataset(df.loc[train_idx, :].reset_index(drop=True), model_path), batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = torch.utils.data.DataLoader(FeedBackDataset(df.loc[valid_idx, :].reset_index(drop=True), model_path), batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    \n",
    "    \n",
    "    net = FeedBackModel(model)\n",
    "    net.cuda()\n",
    "    \n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(net.parameters(), lr = lr)    \n",
    "    param_optimizer = list(net.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    num_train_optimization_steps = int(EPOCHS * len(train_loader) / accumulation_steps)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.05 * num_train_optimization_steps,\n",
    "                                                num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    for epoch in range(EPOCHS):  \n",
    "\n",
    "        start_time = time.time()\n",
    "        avg_loss = 0.0\n",
    "        net.train()\n",
    "        tbar = tqdm(train_loader, file=sys.stdout)\n",
    "        loss_list = []\n",
    "        val_loss_list = []\n",
    "        \n",
    "        for step, data in enumerate(tbar):\n",
    "\n",
    "            # get the inputs\n",
    "            input_ids = data['ids'].cuda()\n",
    "            input_masks = data['mask'].cuda()\n",
    "            targets = data['targets'].long().view(-1).cuda()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = net(input_ids,input_masks)\n",
    "                loss = loss_fn(pred, targets)\n",
    "                \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "\n",
    "            if step % accumulation_steps == 0 or step == len(tbar) - 1:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "                \n",
    "            loss_list.append(loss.detach().cpu().item())\n",
    "            avg_loss = np.round(np.mean(loss_list), 4)\n",
    "\n",
    "            tbar.set_description(f\"Epoch {epoch + 1} Loss: {avg_loss} lr: {scheduler.get_last_lr()}\")\n",
    "        \n",
    "        net.eval()\n",
    "        avg_val_loss = 0.0   \n",
    "        tbar_val = tqdm(val_loader, file=sys.stdout)\n",
    "        for step, data in enumerate(tbar_val):\n",
    "\n",
    "            # get the inputs\n",
    "            input_ids = data['ids'].cuda()\n",
    "            input_masks = data['mask'].cuda()\n",
    "            targets = data['targets'].long().view(-1).cuda()\n",
    "            \n",
    "            pred = net(input_ids,input_masks)\n",
    "            loss = loss_fn(pred, targets)\n",
    "                \n",
    "            val_loss_list.append(loss.detach().cpu().item())\n",
    "            avg_val_loss = np.round(np.mean(val_loss_list), 4)\n",
    "\n",
    "            tbar_val.set_description(f\"Epoch {epoch + 1} Loss: {avg_val_loss}\")\n",
    "                    \n",
    "        cb.put(net, avg_val_loss)   \n",
    "        \n",
    "    model_list.append(cb.get_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6451af95-11b8-43fe-be79-07e6991da4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done generating a model.\n",
    "model_target = \"roberta_modellist.pkl\"\n",
    "with open(model_target,\"wb\") as f:\n",
    "    pickle.dump(model_list, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1e96d-a759-4adb-825b-0fac657bc007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer\n",
    "# https://www.kaggle.com/code/arvissu/roberta-base-inference-v2-0/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11f534bb-47c8-4736-86de-1d59b1cae7d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m      3\u001b[0m MAX_LEN \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[0;32m----> 6\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(FeedBackDataset(test_df, tokenizer, \u001b[38;5;28;01mTrue\u001b[39;00m), batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m model_list \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(model_target, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      8\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(test_df), \u001b[38;5;241m3\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "NFOLDS = 5\n",
    "BATCH_SIZE = 32\n",
    "MAX_LEN = 512\n",
    "\n",
    "\n",
    "model_list = pickle.load(open(model_target, \"rb\"))\n",
    "test_pred = np.zeros((len(test_df), 3))\n",
    "\n",
    "# test_df = pd.read_csv(\"../input/feedback-prize-effectiveness/test.csv\")\n",
    "test_ddf = dd.read_csv(\"../input/feedback-prize-effectiveness/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c268fc6-0d2d-42a3-b061-e5400912fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(test_df: pd.DataFrame, tokenizer, result):\n",
    "    test_loader = torch.utils.data.DataLoader(FeedBackDataset(test_df, tokenizer, True), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            input_ids = data['ids'].cuda()\n",
    "            input_masks = data['mask'].cuda()\n",
    "            pred = F.softmax(net(input_ids,input_masks))\n",
    "            result.extend(pred.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85307221-5ec8-4a70-8627-3873694ad800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mika's note: K-folds is a fairly parallel work as the each batch in folds are normalized to have data parallelism.\n",
    "# Idea hers is to use dask dataframe to handle that part.\n",
    "\n",
    "for idx in range(NFOLDS):\n",
    "    print(f'start to inference fold : {idx}')\n",
    "    net = model_list[idx]\n",
    "    net.eval()\n",
    "    net.cuda()\n",
    "    result = list()\n",
    "    predict(test_ddf, tokenizer, result)\n",
    "    test_pred += np.array(result)/NFOLDS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7b2178-6cae-4725-9244-7a6e3f0036db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(NFOLDS):\n",
    "#     print(f'start to inference fold : {idx}')\n",
    "#     net = model_list[idx]\n",
    "#     net.eval()\n",
    "#     net.cuda()\n",
    "#     result = list()\n",
    "#     with torch.no_grad():\n",
    "#         for i, data in enumerate(test_loader):\n",
    "#             input_ids = data['ids'].cuda()\n",
    "#             input_masks = data['mask'].cuda()\n",
    "#             pred = F.softmax(net(input_ids,input_masks))\n",
    "#             result.extend(pred.cpu().detach().numpy())\n",
    "#     test_pred += np.array(result)/NFOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983743d-a318-4ba1-bf5d-dcab75b15806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our test set predictions\n",
    "test_pred\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
