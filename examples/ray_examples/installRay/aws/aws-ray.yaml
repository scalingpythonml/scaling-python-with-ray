# An unique identifier for the head node and workers of this cluster.
cluster_name: boris

# The minimum number of workers nodes to launch in addition to the head
# node. This number should be >= 0.
min_workers: 0

# The maximum number of workers nodes to launch in addition to the head
# node. This takes precedence over min_workers.
max_workers: 5

# The autoscaler will scale up the cluster faster with higher upscaling speed.
# E.g., if the task requires adding more nodes then autoscaler will gradually
# scale up the cluster in chunks of upscaling_speed*currently_running_nodes.
# This number should be > 0.
upscaling_speed: 1.0

# If a node is idle for this many minutes, it will be removed.
idle_timeout_minutes: 5

# Cloud-provider specific configuration.
provider:
  type: aws
  region: us-east-1
  availability_zone: us-east-1a,us-east-1b
  # Whether to allow node reuse. If set to False, nodes will be terminated
  # instead of stopped.
  cache_stopped_nodes: True # If not present, the default is True.

# How Ray will authenticate with newly launched nodes.
auth:
  ssh_user: ubuntu
# By default Ray creates a new private keypair, but you can also use your own.
# If you do so, make sure to also set "KeyName" in the head and worker node
# configurations below.
#    ssh_private_key: /path/to/your/key.pem

# Provider-specific config for the head node, e.g. instance type. By default
# Ray will auto-configure unspecified fields such as SubnetId and KeyName.
# For more documentation on available fields, see:
# http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.ServiceResource.create_instances
available_node_types:
  ray.head.default:
    node_config:
      InstanceType: m4.large
      ImageId: ami-052efd3df9dad4825  # Default Ubuntu 16.04 AMI.
      KeyName: tigger-team
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: 250
  cpu_8:
    node_config:
      InstanceType: c5n.2xlarge
      ImageId: ami-052efd3df9dad4825  # Default Ubuntu 16.04 AMI.
      KeyName: tigger-team
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            VolumeSize: 250
    min_workers: 0
    max_workers: 5
# List of shell commands to run to set up nodes.
setup_commands:
  # Consider uncommenting these if you run into dpkg locking issues
  #- sudo pkill -9 apt-get || true
  #- sudo pkill -9 dpkg || true
  #- sudo dpkg --configure -a
  # Install basics.
  - sudo apt-get update
  #- sudo apt install software-properties-common -y
  #- sudo add-apt-repository ppa:deadsnakes/ppa -y
  #- sudo apt update
  #- sudo apt-get install -y build-essential curl unzip docker.io
  - sudo apt install -y docker.io
  # Install Anaconda.
  - wget https://repo.continuum.io/archive/Anaconda3-2020.11-Linux-x86_64.sh || true
  - bash Anaconda3-2020.11-Linux-x86_64.sh -b -p $HOME/anaconda || true
  - echo 'export PATH="$HOME/anaconda/bin:$PATH"' >> ~/.bashrc
  - pip install boto3==1.24.43 cython==0.29.32 protobuf==3.20.* aiohttp grpcio psutil setproctitle
  - which ray || pip install ray[default]==2.0.0
  #- sudo usermod -aG docker ubuntu
  #- newgrp docker

# Custom commands that will be run on the head node after common setup.
head_setup_commands: []

# Custom commands that will be run on worker nodes after common setup.
worker_setup_commands: []

# Command to start ray on the head node. You don't need to change this.
head_start_ray_commands:
  - ray stop --force --verbose
  - ulimit -n 65536; ray start --head --port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml --dashboard-host 0.0.0.0

# Command to start ray on worker nodes. You don't need to change this.
worker_start_ray_commands:
  - ray stop --force --verbose
  - ulimit -n 65536; ray start --address=$RAY_HEAD_IP:6379