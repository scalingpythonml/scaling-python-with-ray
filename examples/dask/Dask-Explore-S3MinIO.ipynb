{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask_kubernetes import KubeCluster\n",
    "import numpy as np\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a remote deployment using a load blanacer if we are running the NB outside of the cluster\n",
    "#dask.config.set({\"kubernetes.scheduler-service-type\": \"LoadBalancer\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Clear task state\n",
      "distributed.scheduler - INFO -   Scheduler at:   tcp://10.42.4.201:38419\n",
      "distributed.scheduler - INFO -   dashboard at:                     :8787\n"
     ]
    }
   ],
   "source": [
    "cluster = KubeCluster.from_yaml('worker-spec.yaml', namespace='dask') # deploy_mode='remote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.deploy.adaptive - INFO - Adaptive scaling started: minimum=1 maximum=10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<distributed.deploy.adaptive.Adaptive at 0x7f4b1da910>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.adapt(minimum=1, maximum=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Receive client connection: Client-f5704627-1df8-11eb-8072-6211e88f4455\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.42.4.201:38419</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.42.4.201:8787/status' target='_blank'>http://10.42.4.201:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.42.4.201:38419' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "from dask.distributed import Client\n",
    "import dask.array as da\n",
    "\n",
    "# Connect Dask to the cluster\n",
    "client = Client(cluster)\n",
    "client # the repr gives us useful links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compression': 'lz4', 'python': (3, 8, 6), 'pickle-protocol': 5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.scheduler_comm.comm.handshake_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.42.4.208:38881', name: 0, memory: 0, processing: 64>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.42.4.208:38881\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Create a large array and calculate the mean\n",
    "array = da.ones((1000, 1000, 1000))\n",
    "print(array.mean().compute())  # Should print 1.0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we know the cluster is doing ok :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure dask to talk to our local MinIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The anon false wasted so much time\n",
    "minio_storage_options = {\n",
    "#    \"anon\": \"false\",\n",
    "    \"key\": \"YOURACCESSKEY\",\n",
    "    \"secret\": \"YOURSECRETKEY\",\n",
    "    \"client_kwargs\": {\n",
    "        \"endpoint_url\": \"http://minio-1602984784.minio.svc.cluster.local:9000\",\n",
    "        \"region_name\": 'us-east-1'\n",
    "    },\n",
    "    \"config_kwargs\": {\"s3\": {\"signature_version\": 's3v4'}},\n",
    "}\n",
    "\n",
    "#tag::minio_storage_options[]\n",
    "minio_storage_options = {\n",
    "    \"key\": \"YOURACCESSKEY\",\n",
    "    \"secret\": \"YOURSECRETKEY\",\n",
    "    \"client_kwargs\": {\n",
    "        \"endpoint_url\": \"http://minio-1602984784.minio.svc.cluster.local:9000\",\n",
    "        \"region_name\": 'us-east-1'\n",
    "    },\n",
    "    \"config_kwargs\": {\"s3\": {\"signature_version\": 's3v4'}},\n",
    "}\n",
    "#end::minio_storage_options[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the GH archive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date=datetime.datetime(2020,10,1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::make_file_list[]\n",
    "gh_archive_files=[]\n",
    "while current_date < datetime.datetime.now() -  datetime.timedelta(days=1):\n",
    "    current_date = current_date + datetime.timedelta(hours=1)\n",
    "    datestring = f'{current_date.year}-{current_date.month:02}-{current_date.day:02}-{current_date.hour}'\n",
    "    gh_url = f'http://data.githubarchive.org/{datestring}.json.gz'\n",
    "    gh_archive_files.append(gh_url)\n",
    "#end::make_file_list[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://data.githubarchive.org/2020-10-01-2.json.gz'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_archive_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::load_data[]\n",
    "df = dd.read_json(gh_archive_files, compression='gzip')\n",
    "df.columns\n",
    "#end::load_data[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92084"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file': {'class': 'fsspec.implementations.local.LocalFileSystem'},\n",
       " 'memory': {'class': 'fsspec.implementations.memory.MemoryFileSystem'},\n",
       " 'dropbox': {'class': 'dropboxdrivefs.DropboxDriveFileSystem',\n",
       "  'err': 'DropboxFileSystem requires \"dropboxdrivefs\",\"requests\" and \"dropbox\" to be installed'},\n",
       " 'http': {'class': 'fsspec.implementations.http.HTTPFileSystem',\n",
       "  'err': 'HTTPFileSystem requires \"requests\" and \"aiohttp\" to be installed'},\n",
       " 'https': {'class': 'fsspec.implementations.http.HTTPFileSystem',\n",
       "  'err': 'HTTPFileSystem requires \"requests\" and \"aiohttp\" to be installed'},\n",
       " 'zip': {'class': 'fsspec.implementations.zip.ZipFileSystem'},\n",
       " 'gcs': {'class': 'gcsfs.GCSFileSystem',\n",
       "  'err': 'Please install gcsfs to access Google Storage'},\n",
       " 'gs': {'class': 'gcsfs.GCSFileSystem',\n",
       "  'err': 'Please install gcsfs to access Google Storage'},\n",
       " 'gdrive': {'class': 'gdrivefs.GoogleDriveFileSystem',\n",
       "  'err': 'Please install gdrivefs for access to Google Drive'},\n",
       " 'sftp': {'class': 'fsspec.implementations.sftp.SFTPFileSystem',\n",
       "  'err': 'SFTPFileSystem requires \"paramiko\" to be installed'},\n",
       " 'ssh': {'class': 'fsspec.implementations.sftp.SFTPFileSystem',\n",
       "  'err': 'SFTPFileSystem requires \"paramiko\" to be installed'},\n",
       " 'ftp': {'class': 'fsspec.implementations.ftp.FTPFileSystem'},\n",
       " 'hdfs': {'class': 'fsspec.implementations.hdfs.PyArrowHDFS',\n",
       "  'err': 'pyarrow and local java libraries required for HDFS'},\n",
       " 'webhdfs': {'class': 'fsspec.implementations.webhdfs.WebHDFS',\n",
       "  'err': 'webHDFS access requires \"requests\" to be installed'},\n",
       " 's3': {'class': 's3fs.S3FileSystem', 'err': 'Install s3fs to access S3'},\n",
       " 'adl': {'class': 'adlfs.AzureDatalakeFileSystem',\n",
       "  'err': 'Install adlfs to access Azure Datalake Gen1'},\n",
       " 'abfs': {'class': 'adlfs.AzureBlobFileSystem',\n",
       "  'err': 'Install adlfs to access Azure Datalake Gen2 and Azure Blob Storage'},\n",
       " 'az': {'class': 'adlfs.AzureBlobFileSystem',\n",
       "  'err': 'Install adlfs to access Azure Datalake Gen2 and Azure Blob Storage'},\n",
       " 'cached': {'class': 'fsspec.implementations.cached.CachingFileSystem'},\n",
       " 'blockcache': {'class': 'fsspec.implementations.cached.CachingFileSystem'},\n",
       " 'filecache': {'class': 'fsspec.implementations.cached.WholeFileCacheFileSystem'},\n",
       " 'simplecache': {'class': 'fsspec.implementations.cached.SimpleCacheFileSystem'},\n",
       " 'dask': {'class': 'fsspec.implementations.dask.DaskWorkerFileSystem',\n",
       "  'err': 'Install dask distributed to access worker file system'},\n",
       " 'github': {'class': 'fsspec.implementations.github.GithubFileSystem',\n",
       "  'err': 'Install the requests package to use the github FS'},\n",
       " 'git': {'class': 'fsspec.implementations.git.GitFileSystem',\n",
       "  'err': 'Install pygit2 to browse local git repos'},\n",
       " 'smb': {'class': 'fsspec.implementations.smb.SMBFileSystem',\n",
       "  'err': 'SMB requires \"smbprotocol\" or \"smbprotocol[kerberos]\" installed'},\n",
       " 'jupyter': {'class': 'fsspec.implementations.jupyter.JupyterFileSystem',\n",
       "  'err': 'Jupyter FS requires requests to be installed'},\n",
       " 'jlab': {'class': 'fsspec.implementations.jupyter.JupyterFileSystem',\n",
       "  'err': 'Jupyter FS requires requests to be installed'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What kind of file systems are supported?\n",
    "#tag::known_fs[]\n",
    "from fsspec.registry import known_implementations\n",
    "known_implementations\n",
    "#end::known_fs[]\n",
    "#tag::known_fs_result[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end::known_fs_result[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does our data look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'type', 'actor', 'repo', 'payload', 'public', 'created_at',\n",
       "       'org'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>actor</th>\n",
       "      <th>repo</th>\n",
       "      <th>payload</th>\n",
       "      <th>public</th>\n",
       "      <th>created_at</th>\n",
       "      <th>org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13697091615</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 53307937, 'login': 'randomperson190', '...</td>\n",
       "      <td>{'id': 256356140, 'name': 'randomperson190/Con...</td>\n",
       "      <td>{'push_id': 5779108204, 'size': 1, 'distinct_s...</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-10-01 02:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13697091617</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 14303400, 'login': 'fortyeightbits', 'd...</td>\n",
       "      <td>{'id': 296996950, 'name': 'fortyeightbits/Bobb...</td>\n",
       "      <td>{'push_id': 5779108210, 'size': 1, 'distinct_s...</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-10-01 02:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13697091625</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 50973899, 'login': 'tielm1997', 'displa...</td>\n",
       "      <td>{'id': 300105421, 'name': 'tielm1997/easy_note...</td>\n",
       "      <td>{'push_id': 5779108215, 'size': 1, 'distinct_s...</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-10-01 02:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13697091628</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 70508524, 'login': 'mildredcleveland134...</td>\n",
       "      <td>{'id': 299801944, 'name': 'mildredcleveland134...</td>\n",
       "      <td>{'push_id': 5779108219, 'size': 1, 'distinct_s...</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-10-01 02:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13697091631</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 33073314, 'login': 'sprucelabs-ci', 'di...</td>\n",
       "      <td>{'id': 250079471, 'name': 'sprucelabsai/spruce...</td>\n",
       "      <td>{'push_id': 5779108213, 'size': 1, 'distinct_s...</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-10-01 02:00:00+00:00</td>\n",
       "      <td>{'id': 31485022, 'login': 'sprucelabsai', 'gra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id       type                                              actor  \\\n",
       "0  13697091615  PushEvent  {'id': 53307937, 'login': 'randomperson190', '...   \n",
       "1  13697091617  PushEvent  {'id': 14303400, 'login': 'fortyeightbits', 'd...   \n",
       "2  13697091625  PushEvent  {'id': 50973899, 'login': 'tielm1997', 'displa...   \n",
       "3  13697091628  PushEvent  {'id': 70508524, 'login': 'mildredcleveland134...   \n",
       "4  13697091631  PushEvent  {'id': 33073314, 'login': 'sprucelabs-ci', 'di...   \n",
       "\n",
       "                                                repo  \\\n",
       "0  {'id': 256356140, 'name': 'randomperson190/Con...   \n",
       "1  {'id': 296996950, 'name': 'fortyeightbits/Bobb...   \n",
       "2  {'id': 300105421, 'name': 'tielm1997/easy_note...   \n",
       "3  {'id': 299801944, 'name': 'mildredcleveland134...   \n",
       "4  {'id': 250079471, 'name': 'sprucelabsai/spruce...   \n",
       "\n",
       "                                             payload  public  \\\n",
       "0  {'push_id': 5779108204, 'size': 1, 'distinct_s...    True   \n",
       "1  {'push_id': 5779108210, 'size': 1, 'distinct_s...    True   \n",
       "2  {'push_id': 5779108215, 'size': 1, 'distinct_s...    True   \n",
       "3  {'push_id': 5779108219, 'size': 1, 'distinct_s...    True   \n",
       "4  {'push_id': 5779108213, 'size': 1, 'distinct_s...    True   \n",
       "\n",
       "                 created_at                                                org  \n",
       "0 2020-10-01 02:00:00+00:00                                                NaN  \n",
       "1 2020-10-01 02:00:00+00:00                                                NaN  \n",
       "2 2020-10-01 02:00:00+00:00                                                NaN  \n",
       "3 2020-10-01 02:00:00+00:00                                                NaN  \n",
       "4 2020-10-01 02:00:00+00:00  {'id': 31485022, 'login': 'sprucelabsai', 'gra...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = df.head()\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-0b78b8cb3df5>:2: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  j = pd.io.json.json_normalize(h.repo)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256356140</td>\n",
       "      <td>randomperson190/ControlDeOrganicos</td>\n",
       "      <td>https://api.github.com/repos/randomperson190/C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>296996950</td>\n",
       "      <td>fortyeightbits/BobbinApp</td>\n",
       "      <td>https://api.github.com/repos/fortyeightbits/Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300105421</td>\n",
       "      <td>tielm1997/easy_notes_app</td>\n",
       "      <td>https://api.github.com/repos/tielm1997/easy_no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299801944</td>\n",
       "      <td>mildredcleveland134/helloworld</td>\n",
       "      <td>https://api.github.com/repos/mildredcleveland1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250079471</td>\n",
       "      <td>sprucelabsai/spruce-schema</td>\n",
       "      <td>https://api.github.com/repos/sprucelabsai/spru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                name  \\\n",
       "0  256356140  randomperson190/ControlDeOrganicos   \n",
       "1  296996950            fortyeightbits/BobbinApp   \n",
       "2  300105421            tielm1997/easy_notes_app   \n",
       "3  299801944      mildredcleveland134/helloworld   \n",
       "4  250079471          sprucelabsai/spruce-schema   \n",
       "\n",
       "                                                 url  \n",
       "0  https://api.github.com/repos/randomperson190/C...  \n",
       "1  https://api.github.com/repos/fortyeightbits/Bo...  \n",
       "2  https://api.github.com/repos/tielm1997/easy_no...  \n",
       "3  https://api.github.com/repos/mildredcleveland1...  \n",
       "4  https://api.github.com/repos/sprucelabsai/spru...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "j = pd.io.json.json_normalize(h.repo)\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    randomperson190/ControlDeOrganicos\n",
       "1              fortyeightbits/BobbinApp\n",
       "2              tielm1997/easy_notes_app\n",
       "3        mildredcleveland134/helloworld\n",
       "4            sprucelabsai/spruce-schema\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to partition on the repo name, we need to extract that to it's own column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bag = df.to_bag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The records returned by the bag are tuples not named tuples, so use the df columns to look up the tuple index\n",
    "cols = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_record(record):\n",
    "    r = {\n",
    "        \"repo\": pd.io.json.json_normalize(record[cols.get_loc(\"repo\")]),\n",
    "        \"repo_name\": record[cols.get_loc(\"repo\")][\"name\"],\n",
    "        \"type\": record[cols.get_loc(\"type\")],\n",
    "        \"id\": record[cols.get_loc(\"id\")],\n",
    "        \"created_at\": record[cols.get_loc(\"created_at\")],\n",
    "        \"payload\": pd.io.json.json_normalize(record[cols.get_loc(\"payload\")])}\n",
    "    return r\n",
    "\n",
    "#tag::cleanup[]\n",
    "def clean_record(record):\n",
    "    r = {\n",
    "        \"repo\": record[cols.get_loc(\"repo\")],\n",
    "        \"repo_name\": record[cols.get_loc(\"repo\")][\"name\"],\n",
    "        \"type\": record[cols.get_loc(\"type\")],\n",
    "        \"id\": record[cols.get_loc(\"id\")],\n",
    "        \"created_at\": record[cols.get_loc(\"created_at\")],\n",
    "        \"payload\": record[cols.get_loc(\"payload\")]}\n",
    "    return r\n",
    "\n",
    "cleaned_up_bag = data_bag.map(clean_record)\n",
    "res = cleaned_up_bag.to_dataframe()\n",
    "#end::cleanup[]\n",
    "parsed_bag = data_bag.map(parse_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'repo': {'id': 256356140,\n",
       "   'name': 'randomperson190/ControlDeOrganicos',\n",
       "   'url': 'https://api.github.com/repos/randomperson190/ControlDeOrganicos'},\n",
       "  'repo_name': 'randomperson190/ControlDeOrganicos',\n",
       "  'type': 'PushEvent',\n",
       "  'id': 13697091615,\n",
       "  'created_at': Timestamp('2020-10-01 02:00:00+0000', tz='UTC'),\n",
       "  'payload': {'push_id': 5779108204,\n",
       "   'size': 1,\n",
       "   'distinct_size': 1,\n",
       "   'ref': 'refs/heads/master',\n",
       "   'head': '75aa54756c61184d73064fdfc03a90ab9bc005b6',\n",
       "   'before': '7ee325335c81d127a1e63bd483c3d846fbd479f0',\n",
       "   'commits': [{'sha': '75aa54756c61184d73064fdfc03a90ab9bc005b6',\n",
       "     'author': {'name': 'randomperson190',\n",
       "      'email': '2c19ed4ffbb8866b68a86026e8e0f9eb4284310f@users.noreply.github.com'},\n",
       "     'message': 'Updated',\n",
       "     'distinct': True,\n",
       "     'url': 'https://api.github.com/repos/randomperson190/ControlDeOrganicos/commits/75aa54756c61184d73064fdfc03a90ab9bc005b6'}]}},)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_up_bag.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cleaned_up_bag.to_dataframe()\n",
    "parsed_res = parsed_bag.to_dataframe()\n",
    "h = res.head()\n",
    "h_parsed = parsed_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>payload</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'id': 256356140, 'name': 'randomperson190/Con...</td>\n",
       "      <td>randomperson190/ControlDeOrganicos</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>13697091615</td>\n",
       "      <td>2020-10-01 02:00:00+00:00</td>\n",
       "      <td>{'push_id': 5779108204, 'size': 1, 'distinct_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'id': 296996950, 'name': 'fortyeightbits/Bobb...</td>\n",
       "      <td>fortyeightbits/BobbinApp</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>13697091617</td>\n",
       "      <td>2020-10-01 02:00:00+00:00</td>\n",
       "      <td>{'push_id': 5779108210, 'size': 1, 'distinct_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'id': 300105421, 'name': 'tielm1997/easy_note...</td>\n",
       "      <td>tielm1997/easy_notes_app</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>13697091625</td>\n",
       "      <td>2020-10-01 02:00:00+00:00</td>\n",
       "      <td>{'push_id': 5779108215, 'size': 1, 'distinct_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'id': 299801944, 'name': 'mildredcleveland134...</td>\n",
       "      <td>mildredcleveland134/helloworld</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>13697091628</td>\n",
       "      <td>2020-10-01 02:00:00+00:00</td>\n",
       "      <td>{'push_id': 5779108219, 'size': 1, 'distinct_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'id': 250079471, 'name': 'sprucelabsai/spruce...</td>\n",
       "      <td>sprucelabsai/spruce-schema</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>13697091631</td>\n",
       "      <td>2020-10-01 02:00:00+00:00</td>\n",
       "      <td>{'push_id': 5779108213, 'size': 1, 'distinct_s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                repo  \\\n",
       "0  {'id': 256356140, 'name': 'randomperson190/Con...   \n",
       "1  {'id': 296996950, 'name': 'fortyeightbits/Bobb...   \n",
       "2  {'id': 300105421, 'name': 'tielm1997/easy_note...   \n",
       "3  {'id': 299801944, 'name': 'mildredcleveland134...   \n",
       "4  {'id': 250079471, 'name': 'sprucelabsai/spruce...   \n",
       "\n",
       "                            repo_name       type           id  \\\n",
       "0  randomperson190/ControlDeOrganicos  PushEvent  13697091615   \n",
       "1            fortyeightbits/BobbinApp  PushEvent  13697091617   \n",
       "2            tielm1997/easy_notes_app  PushEvent  13697091625   \n",
       "3      mildredcleveland134/helloworld  PushEvent  13697091628   \n",
       "4          sprucelabsai/spruce-schema  PushEvent  13697091631   \n",
       "\n",
       "                 created_at                                            payload  \n",
       "0 2020-10-01 02:00:00+00:00  {'push_id': 5779108204, 'size': 1, 'distinct_s...  \n",
       "1 2020-10-01 02:00:00+00:00  {'push_id': 5779108210, 'size': 1, 'distinct_s...  \n",
       "2 2020-10-01 02:00:00+00:00  {'push_id': 5779108215, 'size': 1, 'distinct_s...  \n",
       "3 2020-10-01 02:00:00+00:00  {'push_id': 5779108219, 'size': 1, 'distinct_s...  \n",
       "4 2020-10-01 02:00:00+00:00  {'push_id': 5779108213, 'size': 1, 'distinct_s...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(h.iloc[0][\"repo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(h_parsed.iloc[0][\"repo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.42.4.208:38881', name: 0, memory: 0, processing: 1>\n",
      "distributed.core - INFO - Removing comms to tcp://10.42.4.208:38881\n",
      "distributed.scheduler - INFO - Lost all workers\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.42.4.208:34231', name: 0, memory: 0, processing: 1>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.42.4.208:34231\n",
      "distributed.core - INFO - Starting established connection\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.42.2.226:33757', name: 1, memory: 0, processing: 0>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.42.2.226:33757\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dask-test/boop-test-csv/0.part']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to_csv brings it back locally, lets try parquet. csv doesn't handle nesting so well so use original json inside\n",
    "df.to_csv(\"s3://dask-test/boop-test-csv\", storage_options=minio_storage_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Retire worker names (0,)\n",
      "distributed.scheduler - INFO - Retire workers {<Worker 'tcp://10.42.4.208:34231', name: 0, memory: 0, processing: 0>}\n",
      "distributed.scheduler - INFO - Closing worker tcp://10.42.4.208:34231\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.42.4.208:34231', name: 0, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.42.4.208:34231\n",
      "distributed.deploy.adaptive - INFO - Retiring workers [0]\n"
     ]
    }
   ],
   "source": [
    "# This will probably still bring everything back to the client? I'm guessing though.\n",
    "res.to_parquet(\"s3://dask-test/boop-test-pq\", compression=\"gzip\", storage_options=minio_storage_options, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.42.2.226:33757', name: 1, memory: 0, processing: 1>\n",
      "distributed.core - INFO - Removing comms to tcp://10.42.2.226:33757\n",
      "distributed.scheduler - INFO - Lost all workers\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.42.2.226:41689', name: 1, memory: 0, processing: 1>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.42.2.226:41689\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error converting column \"repo\" to bytes using encoding UTF8. Original error: bad argument type for built-in operation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3f4507416e61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparsed_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s3://dask-test/boop-test-pq-p-nested\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminio_storage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fastparquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/dask/dataframe/core.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(self, path, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3972\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3974\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3976\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mderived_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, write_index, append, ignore_divisions, partition_on, storage_options, write_metadata_file, compute, compute_kwargs, schema, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompute_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mcompute_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcompute_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2723\u001b[0m                     \u001b[0mshould_rejoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2725\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2726\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2727\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1984\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m                 \u001b[0mlocal_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m             return self.sync(\n\u001b[0m\u001b[1;32m   1987\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gather\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m                 \u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m             return sync(\n\u001b[0m\u001b[1;32m    833\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_timeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tornado/gen.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m                         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                         \u001b[0mexc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   1849\u001b[0m                             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1851\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1852\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"skip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/dask/utils.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/dask/dataframe/io/parquet/fastparquet.py\u001b[0m in \u001b[0;36mwrite_partition\u001b[0;34m()\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0mfmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m                 rg = make_part_file(\n\u001b[0m\u001b[1;32m    625\u001b[0m                     \u001b[0mfil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                 )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/fastparquet/writer.py\u001b[0m in \u001b[0;36mmake_part_file\u001b[0;34m()\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMARKER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0mrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_row_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfmd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             fmd = parquet_thrift.FileMetaData(num_rows=rg.num_rows,\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/fastparquet/writer.py\u001b[0m in \u001b[0;36mmake_row_group\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mcomp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m             chunk = write_column(f, data[column.name], column,\n\u001b[0m\u001b[1;32m    619\u001b[0m                                  compression=comp)\n\u001b[1;32m    620\u001b[0m             \u001b[0mrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/fastparquet/writer.py\u001b[0m in \u001b[0;36mwrite_column\u001b[0;34m()\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m     bdata = definition_data + repetition_data + encode[encoding](\n\u001b[0m\u001b[1;32m    513\u001b[0m             data, selement)\n\u001b[1;32m    514\u001b[0m     \u001b[0mbdata\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34mb'\\x00'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/fastparquet/writer.py\u001b[0m in \u001b[0;36mencode_plain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode_plain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;34m\"\"\"PLAIN encoding; returns byte representation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mparquet_thrift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTE_ARRAY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpack_byte_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/fastparquet/writer.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m()\u001b[0m\n\u001b[1;32m    193\u001b[0m             ct = parquet_thrift.ConvertedType._VALUES_TO_NAMES[\n\u001b[1;32m    194\u001b[0m                 converted_type] if converted_type is not None else None\n\u001b[0;32m--> 195\u001b[0;31m             raise ValueError('Error converting column \"%s\" to bytes using '\n\u001b[0m\u001b[1;32m    196\u001b[0m                              \u001b[0;34m'encoding %s. Original error: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                              '%s' % (data.name, ct, e))\n",
      "\u001b[0;31mValueError\u001b[0m: Error converting column \"repo\" to bytes using encoding UTF8. Original error: bad argument type for built-in operation"
     ]
    }
   ],
   "source": [
    "parsed_res.to_parquet(\"s3://dask-test/boop-test-pq-p-nested\", compression=\"gzip\", storage_options=minio_storage_options, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.42.2.226:41689', name: 1, memory: 0, processing: 1>\n",
      "distributed.core - INFO - Removing comms to tcp://10.42.2.226:41689\n",
      "distributed.scheduler - INFO - Lost all workers\n",
      "distributed.scheduler - INFO - Register worker <Worker 'tcp://10.42.2.226:45549', name: 1, memory: 0, processing: 1>\n",
      "distributed.scheduler - INFO - Starting worker compute stream, tcp://10.42.2.226:45549\n",
      "distributed.core - INFO - Starting established connection\n"
     ]
    }
   ],
   "source": [
    "#tag::write[]\n",
    "res.to_parquet(\"s3://dask-test/boop-test-partioned\",\n",
    "              partition_on=[\"type\", \"repo_name\"], # Based on \" there will be no global groupby.\" I think this is the value we want.\n",
    "              compression=\"gzip\",\n",
    "              storage_options=minio_storage_options, engine=\"pyarrow\")\n",
    "#end::write[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
