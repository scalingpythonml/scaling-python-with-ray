{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff240d-ef45-4f33-8944-07d239531ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from typing import *\n",
    "import dask\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55a6b2d-8de8-40aa-a904-01992ac54840",
   "metadata": {},
   "outputs": [],
   "source": [
    "local=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb05c3b-8ddf-4ef5-82df-49e628aa16e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local:\n",
    "    ray.init(num_cpus=30)\n",
    "else:\n",
    "    # Connect to the ray cluster\n",
    "    CLUSTER_NAME = \"gpu-cluster\"\n",
    "    NAMESPACE = \"ray\"\n",
    "    PORT=10001\n",
    "    # The dns name is based off of the service name which is [cluster]-ray-head & namespace\n",
    "    dns_name = f\"{CLUSTER_NAME}-ray-head.{NAMESPACE}.svc\"\n",
    "    ray.util.connect(f\"{dns_name}:{PORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a4dbe2-f8fb-43f2-bdd5-869b486105bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525951c-a5c8-44c0-bbae-fe607ba8f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "trivial_ds = ray.data.from_items([\n",
    "    \"https://github.com/scalingpythonml/scalingpythonml\",\n",
    "    \"https://github.com/ray-project/ray\"])\n",
    "ray.get(trivial_ds.get_internal_block_refs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67001e59-d5f5-4bcc-8155-d5684267e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://gender-pay-gap.service.gov.uk/viewing/download-data/2021\n",
    "!mv 2021 2021.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d1b97-af26-4bd5-976d-22061ef0e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If in local mode\n",
    "if local:\n",
    "    #tag::load_csv_local_fs[]\n",
    "    ds = ray.data.read_csv(\"2021.csv\")\n",
    "    #end::looad_csv_local_fs[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3bb0d7-b6f8-47dc-bb5c-3a2e7a4a40d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5cf6cf-1d7e-41fe-b4f6-ded37ac23e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fsspec.registry import known_implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0d712-5df0-42e1-9db2-273197431ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsspec.filesystem('http')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c227450-589a-4e10-846a-f4dd6e13c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96def58-7be7-4e60-8985-277707fd77ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    fsspec.filesystem('gcs')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb722d43-d462-482d-8ef3-35d27a9d572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: broken in latest version of Ray (see https://github.com/ray-project/ray/issues/26605 ) works in previous\n",
    "#tag::load_from_https[]\n",
    "fs = fsspec.filesystem('https')\n",
    "ds = ray.data.read_csv(\n",
    "    \"https://https://gender-pay-gap.service.gov.uk/viewing/download-data/2021\",\n",
    "    filesystem=fs)\n",
    "#end::load_from_https[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6dab0-d53b-4b19-b4e2-8c178d3b977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.get(ds.get_internal_block_refs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda13c0-b07f-4e80-9f09-000e0d966f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.util import inspect_serializability\n",
    "inspect_serializability(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14643524-3851-4353-832c-9af0b879922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_serializability(ray.get(ds.get_internal_block_refs()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c04ba-fee8-497f-817a-2b2b12c419e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::batch_op_on_pandas[]\n",
    "# Kind of hacky string munging to get a median-ish to weight our values.\n",
    "def update_empsize_to_median(df):\n",
    "    def to_median(value):\n",
    "        if \" to \" in value:\n",
    "            f , t = value.replace(\",\", \"\").split(\" to \")\n",
    "            return (int(f) + int(t)) / 2.0\n",
    "        elif \"Less than\" in value:\n",
    "            return 100\n",
    "        else:\n",
    "            return 10000\n",
    "    df[\"EmployerSize\"] = df[\"EmployerSize\"].apply(to_median)\n",
    "    return df\n",
    "\n",
    "ds_with_median = ds.map_batches(update_empsize_to_median, batch_format=\"pandas\")\n",
    "#end::batch_op_on_pandas[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ca75c-13a4-49ef-9844-f7371b3f404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::agg[]\n",
    "def init_func(key):\n",
    "    # First elem is weighted total, second is weights\n",
    "    return [0, 0]\n",
    "\n",
    "def accumulate_func(accumulated, row):\n",
    "    return [\n",
    "        accumulated[0] + (float(row[\"EmployerSize\"]) * float(row[\"DiffMeanHourlyPercent\"])),\n",
    "        accumulated[1] + row[\"DiffMeanHourlyPercent\"]]\n",
    "        \n",
    "def combine_aggs(agg1, agg2):\n",
    "    return (agg1[0] + agg2[0], agg1[1] + agg2[1])\n",
    "\n",
    "def finalize(agg):\n",
    "    if agg[1] != 0:\n",
    "        return agg[0] / agg[1]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "weighted_mean = ray.data.aggregate.AggregateFn(\n",
    "    name='weighted_mean',\n",
    "    init=init_func,\n",
    "    merge=combine_aggs,\n",
    "    accumulate_row=accumulate_func, # Used to be accumulate\n",
    "    # There is a higher performance option called accumulate_block for vectorized op\n",
    "    finalize=finalize)\n",
    "aggregated = ds_with_median.groupby(\"PostCode\").aggregate(weighted_mean)\n",
    "#end::agg[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3ac9b-ecd3-4bd9-b4f5-37aee63384e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfae549-53ad-4161-8fdf-4ad84f8696dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::batch_op_on_pandas_from_raw[]\n",
    "def sup(df):\n",
    "    return list(str(df.info()))\n",
    "\n",
    "trivial_ds.map_batches(sup, batch_format=\"pandas\")\n",
    "#end::batch_op_on_pandas_from_raw[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55e72d-0d96-4164-8b76-1e456b57bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_with_median.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f21fe59-ffb3-4ca5-b7df-10889eaf425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::enable_dask[]\n",
    "from ray.util.dask import enable_dask_on_ray, disable_dask_on_ray\n",
    "enable_dask_on_ray() # Routes all Dask calls through the Ray scheduler\n",
    "#end::enable_dask[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57bf058-e287-426f-bda3-d2c099bd8202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::to_dask[]\n",
    "dask_df = ds.to_dask()\n",
    "#end::to_dask[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d8e27b-1e20-4b54-9201-2b9669542876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::enable_spark[]\n",
    "import raydp\n",
    "spark = raydp.init_spark(\n",
    "  app_name = \"sleepy\",\n",
    "  num_executors = 2,\n",
    "  executor_cores = 1,\n",
    "  executor_memory = \"2GB\"\n",
    ")\n",
    "#end::enable_spark[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ef5614-51bb-4fe9-82e9-d9895223bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::to_spark[]\n",
    "spark_df = ds.to_spark()\n",
    "#end::to_spark[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b884d5-2997-4d00-9396-7b9ca8bf15ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::ds[]\n",
    "# Create a Dataset of URLS objects. We could also load this from a text file with ray.data.read_text()\n",
    "urls = ray.data.from_items([\n",
    "    \"https://github.com/scalingpythonml/scalingpythonml\",\n",
    "    \"https://github.com/ray-project/ray\"])\n",
    "\n",
    "def fetch_page(url):\n",
    "    import requests\n",
    "    f = requests.get(url)\n",
    "    return f.text\n",
    "\n",
    "pages = urls.map(fetch_page)\n",
    "# Look at a page to make sure it worked\n",
    "pages.take(1)\n",
    "#end::ds[]\n",
    "#tag::ray_wordcount_on_ds_filter_only_once[]\n",
    "words = pages.flat_map(lambda x: x.split(\" \")).map(lambda w: (w, 1))\n",
    "grouped_words = words.groupby(lambda wc: wc[0])\n",
    "interesting_words = groupd_words.filter(lambda wc: wc[1] > 1)\n",
    "#end::ray_wordcount_on_ds_filter_only_once[]\n",
    "interesting_words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31caea2d-bf59-48b5-9ff9-dda23164769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::ray_wordcount_on_ds_filter_only_once_with_batches[]\n",
    "def tokenize_batch(batch):\n",
    "    nested_tokens = map(lambda s: s.split(\" \"), batch)\n",
    "    # Flatten the result\n",
    "    nr = []\n",
    "    for r in nested_tokens:\n",
    "        nr.extend(r)\n",
    "    return nr\n",
    "\n",
    "def pair_batch(batch):\n",
    "    return list(map(lambda w: (w, 1), batch))\n",
    "\n",
    "def filter_for_interesting(batch):\n",
    "    return list(filter(lambda wc: wc[1] > 1, batch))\n",
    "\n",
    "words = pages.map_batches(tokenize_batch).map_batches(pair_batch)\n",
    "# The one part we can't rewrite with map_batches since it involves a shuffle\n",
    "grouped_words = words.groupby(lambda wc: wc[0]) \n",
    "interesting_words = groupd_words.map_batches(filter_for_interesting)\n",
    "#end::ray_wordcount_on_ds_filter_only_once_with_batches[]\n",
    "interesting_words.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdfe7c2-d8bc-4a9c-afb3-c284a96f3ca3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note to holden - move this to the dataset chapter for showing how to integrate with remote functions\n",
    "# and talk about why.\n",
    "#tag::more_awesome_wordcount[]\n",
    "runtime_env = {\"pip\": [\"bs4\"]}\n",
    "parse_env = {\"pip\": [\"bs4\", \"nltk\"]}\n",
    "\n",
    "# Note - not remote\n",
    "def fetch(url: str) -> Tuple[str, str]:\n",
    "    import urllib.request\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "       return (url, response.read())\n",
    "\n",
    "# This is remote because we want to use bs4\n",
    "@ray.remote(runtime_env=runtime_env)\n",
    "def extract_text(url_text: Tuple[str, str]) -> str:\n",
    "    from bs4 import BeautifulSoup\n",
    "    html = url_text[1]\n",
    "    return str(BeautifulSoup(html, 'html.parser').text)\n",
    "\n",
    "# This is remote because we want to use nltk\n",
    "@ray.remote(runtime_env=parse_env)\n",
    "def tokenize(text: str):\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    return list(word_tokenize(text))\n",
    "\n",
    "urls = ray.data.from_items([\"http://www.holdenkarau.com\", \"http://www.google.com\"])\n",
    "\n",
    "pages = urls.map(fetch)\n",
    "# This \n",
    "page_text = pages.map(lambda r: ray.get(extract_text.remote(r)))\n",
    "words = page_text.flat_map(lambda r: ray.get(tokenize.remote(r)))\n",
    "word_count = words.groupby(lambda x: x).count()\n",
    "word_count.show()\n",
    "#end::more_awesome_wordcount[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eac184-2a96-4f43-88c0-10429d4b9bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::more_awesome_wordcount_with_batches[]\n",
    "def extract_text_for_batch(sites):\n",
    "    text_futures = map(lambda s: extract_text.remote(s), sites)\n",
    "    result = ray.get(list(text_futures))\n",
    "    # ray.get returns None on an empty input, but map_batches requires lists\n",
    "    if result is None:\n",
    "        return []\n",
    "    return result\n",
    "\n",
    "def tokenize_batch(texts):\n",
    "    token_futures = map(lambda s: tokenize.remote(s), texts)\n",
    "    result = ray.get(list(token_futures))\n",
    "    if result is None:\n",
    "        return []\n",
    "    # Flatten the result\n",
    "    nr = []\n",
    "    for r in result:\n",
    "        nr.extend(r)\n",
    "    return nr\n",
    "\n",
    "\n",
    "# Exercise to the reader: generalize the above patterns - note the flatten magic difference\n",
    "\n",
    "urls = ray.data.from_items([\"http://www.holdenkarau.com\", \"http://www.google.com\"])\n",
    "\n",
    "pages = urls.map(fetch)\n",
    "\n",
    "page_text = pages.map_batches(extract_text_for_batch)\n",
    "words = page_text.map_batches(tokenize_batch)\n",
    "word_count = words.groupby(lambda x: x).count()\n",
    "word_count.show()\n",
    "#tag::more_awesome_wordcount_with_batches[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65265fb7-46d6-42c6-a1b2-d2efa08170bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::wc_write[]\n",
    "word_count.write_csv(\"s3://ray-demo/wc\")\n",
    "#end::wc_write[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
